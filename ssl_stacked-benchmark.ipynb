{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import notebook_util\n",
    "notebook_util.setup_one_gpu()\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import logpdf\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(31415)\n",
    "np.random.seed(31415)\n",
    "tf.set_random_seed(31415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.layers as tcl\n",
    "class SSL:\n",
    "    def __init__(self, x_dim = 50):\n",
    "        self.name = 'SSL'\n",
    "        \n",
    "        # classifier params\n",
    "        self.hidden_size = 500\n",
    "        self.num_labels = 10\n",
    "        \n",
    "        # encode & decoder params\n",
    "        self.z_dim = 50\n",
    "        self.x_dim = x_dim\n",
    "        self.batch_size   = 500\n",
    "        self.dataset_size = 50000\n",
    "        \n",
    "        # training\n",
    "        self.lr_decay_factor = 0.95\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        with tf.variable_scope(self.name):\n",
    "            self._build_annealing()\n",
    "            self._build_graph()\n",
    "            self._build_train_op()\n",
    "        self.check_parameters()\n",
    "    \n",
    "    def global_vars(self):\n",
    "        var_list = [var for var in tf.global_variables() if self.name in var.name]\n",
    "        return var_list\n",
    "    \n",
    "    def trainable_vars(self):\n",
    "        var_list = [var for var in tf.trainable_variables() if self.name in var.name]\n",
    "        return var_list\n",
    "    \n",
    "    def check_parameters(self):\n",
    "        for var in tf.trainable_variables():\n",
    "            print('%s: %s' % (var.name, var.get_shape()))\n",
    "        print()\n",
    "    \n",
    "    def get_collection(self, collections):\n",
    "        return [var for var in tf.get_collection(collections)]\n",
    "    \n",
    "    def classify(self, x, reuse = False):\n",
    "        with tf.variable_scope('classifier', reuse = reuse):\n",
    "            h = tcl.fully_connected(x, self.hidden_size, activation_fn = tf.nn.softplus)\n",
    "            y = tcl.fully_connected(h, self.num_labels,  activation_fn = tf.nn.softplus)\n",
    "            return y\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = tf.exp(logvar * 0.5)\n",
    "        eps = tf.random_normal(tf.shape(mu))\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def encode(self, x, y, reuse = False):\n",
    "        with tf.variable_scope('encoder', reuse = reuse):\n",
    "            concat = tf.concat([x, y], 1)\n",
    "            h = tcl.fully_connected(concat, self.hidden_size, activation_fn = tf.nn.softplus)\n",
    "            mu     = tcl.fully_connected(h, self.z_dim, activation_fn = None)\n",
    "            logvar = tcl.fully_connected(h, self.z_dim, activation_fn = None)\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            return z, mu, logvar\n",
    "    \n",
    "    def decode(self, z, y, reuse = False):\n",
    "        with tf.variable_scope('decoder', reuse = reuse):\n",
    "            concat = tf.concat([z, y], 1)\n",
    "            h = tcl.fully_connected(concat, self.hidden_size, activation_fn = tf.nn.softplus)\n",
    "            mu     = tcl.fully_connected(h, self.x_dim, activation_fn = None)\n",
    "            logvar = tcl.fully_connected(h, self.x_dim, activation_fn = None)\n",
    "            return mu, logvar\n",
    "        \n",
    "    def likelihood(self, x, mu_x, logvar_x, y, z, mu_z, logvar_z):\n",
    "        # uniform prior\n",
    "        prior_y = (1. / self.num_labels) * tf.ones([tf.shape(x)[0], 10], tf.float32)\n",
    "        logpy = - tf.nn.softmax_cross_entropy_with_logits(logits = prior_y, labels = y)\n",
    "        \n",
    "        kld = tf.reduce_sum(logpdf.KLD(mu_z, logvar_z), 1)\n",
    "        logpx = tf.reduce_sum(logpdf.gaussian(x, mu_x, logvar_x), 1)\n",
    "        likelihood = logpx + logpy - kld  \n",
    "        return likelihood\n",
    "    \n",
    "    def prior_likelihood(self):\n",
    "        likelihood = 0\n",
    "        vars = self.trainable_vars()\n",
    "        for var in vars:\n",
    "            likelihood += tf.reduce_sum(logpdf.std_gaussian(var))\n",
    "        return likelihood\n",
    "    \n",
    "    def _build_graph(self, reuse = False):\n",
    "        self.x_l = tf.placeholder(tf.float32, shape = (None, self.x_dim))\n",
    "        self.y_l = tf.placeholder(tf.int32, shape = (None, ))\n",
    "        self.x_u = tf.placeholder(tf.float32, shape = (None, self.x_dim))\n",
    "        \n",
    "        self.y_l_onehot = tcl.one_hot_encoding(self.y_l, num_classes = self.num_labels)\n",
    "                \n",
    "        '''\n",
    "            classifier, labelled\n",
    "        '''\n",
    "        scores_l = self.classify(self.x_l, reuse = reuse)\n",
    "        # loss of classifier\n",
    "        self.loss_clf = tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "                        logits = scores_l, labels = self.y_l_onehot )\n",
    "\n",
    "        '''\n",
    "            labelled data, encoder & decoder\n",
    "        '''\n",
    "        z_l, mu_z_l, logvar_z_l = self.encode(self.x_l, self.y_l_onehot, reuse = reuse)\n",
    "        mu_x_l, logvar_x_l = self.decode(z_l, self.y_l_onehot, reuse = reuse)\n",
    "        \n",
    "        # loss of labelled data, refered as L(x, y)\n",
    "        self.likelihood_l = self.likelihood(self.x_l, mu_x_l, logvar_x_l, \\\n",
    "                                            self.y_l_onehot, z_l, mu_z_l, logvar_z_l)\n",
    "        \n",
    "        '''\n",
    "            unlabelled data, encoder & decoder\n",
    "        '''\n",
    "        for i in range(self.num_labels):\n",
    "            y_us = i*tf.ones([tf.shape(self.x_u)[0]], tf.int32)\n",
    "            y_us = tcl.one_hot_encoding(y_us, num_classes = self.num_labels)\n",
    "            \n",
    "            z_u, mu_u, logvar_u = self.encode(self.x_u, y_us, reuse = True)\n",
    "            mu_recon_u, logvar_recon_u = self.decode(z_u, y_us, reuse = True)\n",
    "            \n",
    "            _likelihood_u = self.likelihood(self.x_u, mu_recon_u, logvar_recon_u,\\\n",
    "                                y_us, z_u, mu_u, logvar_u)\n",
    "            _likelihood_u = tf.expand_dims(_likelihood_u, 1)\n",
    "            \n",
    "            if i == 0:\n",
    "                likelihood_u = tf.identity( _likelihood_u )\n",
    "            else:\n",
    "                likelihood_u = tf.concat([likelihood_u, _likelihood_u], 1)\n",
    "            \n",
    "        # with x & clf, give the dist over y\n",
    "        scores_u = self.classify(self.x_u, reuse = True)\n",
    "        y_u_prob = tf.nn.softmax(scores_u, dim=-1)\n",
    "        \n",
    "        # add the H(q(y|x))\n",
    "        likelihood_u = tf.multiply(y_u_prob, likelihood_u + -tf.log(y_u_prob)) \n",
    "        likelihood_u = tf.reduce_sum(likelihood_u, 1)\n",
    "\n",
    "        alpha = 0.1 * self.batch_size\n",
    "        self.loss_clf = tf.reduce_sum(self.loss_clf, 0)\n",
    "        self.loss_l = - tf.reduce_sum(self.likelihood_l, 0)\n",
    "        self.loss_u = - tf.reduce_sum(self.likelihood_u, 0)\n",
    "        self.loss = (self.loss_l + alpha* self.loss_clf + self.loss_u)/self.batch_size\n",
    "\n",
    "        print('loss_u  : '+str(self.loss_u.shape))\n",
    "        print('loss_l  : '+str(self.loss_l.shape))\n",
    "        print('loss_clf: '+str(self.loss_clf.shape))\n",
    "        \n",
    "        prior_weight = 1./(self.dataset_size) \n",
    "        self.loss_prior = - self.prior_likelihood()\n",
    "        self.loss += prior_weight * self.loss_prior\n",
    "        \n",
    "        self.pred_y = tf.argmax(scores_u, 1)\n",
    "    \n",
    "    def _build_train_op(self):\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable = False)\n",
    "        self.lr = tf.Variable(self.learning_rate, trainable=False, \n",
    "                    dtype=tf.float32)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        grads_and_vars = optimizer.compute_gradients(self.loss)\n",
    "        def ClipIfNotNone(grad):\n",
    "            if grad is None:\n",
    "                return grad\n",
    "            return tf.clip_by_value(grad, -1, 1)\n",
    "        capped_gvs = [(ClipIfNotNone(grad), var) for grad, var in grads_and_vars]\n",
    "        self.train_op = optimizer.apply_gradients(capped_gvs, self.global_step)\n",
    "        self.lr_decay_op = self.lr.assign(\n",
    "                self.lr * self.lr_decay_factor)\n",
    "    \n",
    "    def lr_decay(self, sess):\n",
    "        _ = sess.run([self.lr_decay_op])\n",
    "        \n",
    "    def _build_annealing(self):\n",
    "        self.kld_weight = tf.Variable(float(0.0), trainable=False, \n",
    "                                    dtype=tf.float32)\n",
    "        kld_anneal_factor = 0.95\n",
    "        self.anneal_decay_op = self.kld_weight.assign(\n",
    "                self.kld_weight * kld_anneal_factor)\n",
    "\n",
    "    def kld_anneal(self, sess):\n",
    "        _ = sess.run([self.anneal_decay_op])\n",
    "    \n",
    "    def predict(self, x, sess):\n",
    "        feed_dict = {\n",
    "            self.x_u: x,\n",
    "        }\n",
    "        pred = sess.run([self.pred_y], feed_dict = feed_dict)[0]\n",
    "        return pred\n",
    "    \n",
    "    def optimize(self, sess, x_l, y_l, x_u):\n",
    "        feed_dict = {\n",
    "            self.x_l: x_l,\n",
    "            self.y_l: y_l,\n",
    "\n",
    "            self.x_u: x_u,\n",
    "        }\n",
    "        eval_train = [self.train_op, self.loss]\n",
    "        eval_loss  = [self.loss_clf, self.loss_l, self.loss_u, self.loss_prior]\n",
    "        eval_vars = eval_train + eval_loss\n",
    "        _, loss, loss_clf, loss_l, loss_u, loss_p = sess.run(eval_vars, feed_dict = feed_dict)\n",
    "        return loss, loss_clf, loss_l, loss_u, loss_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_u  : (?,)\n",
      "loss_l  : (?,)\n",
      "loss_clf: (?,)\n",
      "SSL/classifier/fully_connected/weights:0: (15, 500)\n",
      "SSL/classifier/fully_connected/biases:0: (500,)\n",
      "SSL/classifier/fully_connected_1/weights:0: (500, 10)\n",
      "SSL/classifier/fully_connected_1/biases:0: (10,)\n",
      "SSL/encoder/fully_connected/weights:0: (25, 500)\n",
      "SSL/encoder/fully_connected/biases:0: (500,)\n",
      "SSL/encoder/fully_connected_1/weights:0: (500, 50)\n",
      "SSL/encoder/fully_connected_1/biases:0: (50,)\n",
      "SSL/encoder/fully_connected_2/weights:0: (500, 50)\n",
      "SSL/encoder/fully_connected_2/biases:0: (50,)\n",
      "SSL/decoder/fully_connected/weights:0: (60, 500)\n",
      "SSL/decoder/fully_connected/biases:0: (500,)\n",
      "SSL/decoder/fully_connected_1/weights:0: (500, 15)\n",
      "SSL/decoder/fully_connected_1/biases:0: (15,)\n",
      "SSL/decoder/fully_connected_2/weights:0: (500, 15)\n",
      "SSL/decoder/fully_connected_2/biases:0: (15,)\n",
      "\n",
      "time: 0 m 5 s\n",
      "epoch: 0\n",
      "  labelled loss: 22.20\n",
      "unlabelled loss: 10867.78\n",
      "classifier loss: 2.20\n",
      "     prior loss: 111998.81\n",
      "     total loss: 24.24\n",
      " valid accuracy: 0.277\n",
      "  test accuracy: 0.272\n",
      "\n",
      "time: 0 m 52 s\n",
      "epoch: 10\n",
      "  labelled loss: 21.89\n",
      "unlabelled loss: 10651.16\n",
      "classifier loss: 0.93\n",
      "     prior loss: 112002.69\n",
      "     total loss: 23.68\n",
      " valid accuracy: 0.721\n",
      "  test accuracy: 0.707\n",
      "\n",
      "time: 1 m 40 s\n",
      "epoch: 20\n",
      "  labelled loss: 23.11\n",
      "unlabelled loss: 10557.39\n",
      "classifier loss: 0.18\n",
      "     prior loss: 112039.05\n",
      "     total loss: 23.42\n",
      " valid accuracy: 0.842\n",
      "  test accuracy: 0.829\n",
      "\n",
      "time: 2 m 28 s\n",
      "epoch: 30\n",
      "  labelled loss: 20.25\n",
      "unlabelled loss: 10464.90\n",
      "classifier loss: 0.95\n",
      "     prior loss: 112072.27\n",
      "     total loss: 23.31\n",
      " valid accuracy: 0.871\n",
      "  test accuracy: 0.862\n",
      "\n",
      "time: 3 m 16 s\n",
      "epoch: 40\n",
      "  labelled loss: 20.27\n",
      "unlabelled loss: 10436.45\n",
      "classifier loss: 0.01\n",
      "     prior loss: 112084.20\n",
      "     total loss: 23.16\n",
      " valid accuracy: 0.877\n",
      "  test accuracy: 0.867\n",
      "\n",
      "time: 4 m 4 s\n",
      "epoch: 50\n",
      "  labelled loss: 21.11\n",
      "unlabelled loss: 10433.45\n",
      "classifier loss: 1.12\n",
      "     prior loss: 112091.73\n",
      "     total loss: 23.26\n",
      " valid accuracy: 0.880\n",
      "  test accuracy: 0.871\n",
      "\n",
      "time: 4 m 52 s\n",
      "epoch: 60\n",
      "  labelled loss: 20.36\n",
      "unlabelled loss: 10348.14\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112098.34\n",
      "     total loss: 22.98\n",
      " valid accuracy: 0.879\n",
      "  test accuracy: 0.869\n",
      "\n",
      "time: 5 m 40 s\n",
      "epoch: 70\n",
      "  labelled loss: 17.76\n",
      "unlabelled loss: 10394.55\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112105.16\n",
      "     total loss: 23.07\n",
      " valid accuracy: 0.886\n",
      "  test accuracy: 0.875\n",
      "\n",
      "time: 6 m 29 s\n",
      "epoch: 80\n",
      "  labelled loss: 27.98\n",
      "unlabelled loss: 10531.01\n",
      "classifier loss: 0.17\n",
      "     prior loss: 112112.47\n",
      "     total loss: 23.38\n",
      " valid accuracy: 0.884\n",
      "  test accuracy: 0.875\n",
      "\n",
      "time: 7 m 17 s\n",
      "epoch: 90\n",
      "  labelled loss: 17.48\n",
      "unlabelled loss: 10437.28\n",
      "classifier loss: 0.06\n",
      "     prior loss: 112120.84\n",
      "     total loss: 23.16\n",
      " valid accuracy: 0.887\n",
      "  test accuracy: 0.878\n",
      "\n",
      "time: 8 m 5 s\n",
      "epoch: 100\n",
      "  labelled loss: 18.48\n",
      "unlabelled loss: 10502.93\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112129.50\n",
      "     total loss: 23.29\n",
      " valid accuracy: 0.887\n",
      "  test accuracy: 0.878\n",
      "\n",
      "time: 8 m 53 s\n",
      "epoch: 110\n",
      "  labelled loss: 14.66\n",
      "unlabelled loss: 10405.74\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112139.65\n",
      "     total loss: 23.08\n",
      " valid accuracy: 0.890\n",
      "  test accuracy: 0.880\n",
      "\n",
      "time: 9 m 41 s\n",
      "epoch: 120\n",
      "  labelled loss: 20.47\n",
      "unlabelled loss: 10356.62\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112150.83\n",
      "     total loss: 23.00\n",
      " valid accuracy: 0.892\n",
      "  test accuracy: 0.882\n",
      "\n",
      "time: 10 m 30 s\n",
      "epoch: 130\n",
      "  labelled loss: 26.01\n",
      "unlabelled loss: 10361.87\n",
      "classifier loss: 0.26\n",
      "     prior loss: 112162.67\n",
      "     total loss: 23.05\n",
      " valid accuracy: 0.893\n",
      "  test accuracy: 0.884\n",
      "\n",
      "time: 11 m 18 s\n",
      "epoch: 140\n",
      "  labelled loss: 27.25\n",
      "unlabelled loss: 10318.79\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112175.58\n",
      "     total loss: 22.94\n",
      " valid accuracy: 0.896\n",
      "  test accuracy: 0.887\n",
      "\n",
      "time: 12 m 6 s\n",
      "epoch: 150\n",
      "  labelled loss: 20.10\n",
      "unlabelled loss: 10269.77\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112190.00\n",
      "     total loss: 22.82\n",
      " valid accuracy: 0.898\n",
      "  test accuracy: 0.889\n",
      "\n",
      "time: 12 m 55 s\n",
      "epoch: 160\n",
      "  labelled loss: 16.95\n",
      "unlabelled loss: 10420.80\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112204.70\n",
      "     total loss: 23.12\n",
      " valid accuracy: 0.902\n",
      "  test accuracy: 0.892\n",
      "\n",
      "time: 13 m 44 s\n",
      "epoch: 170\n",
      "  labelled loss: 23.57\n",
      "unlabelled loss: 10364.84\n",
      "classifier loss: 0.05\n",
      "     prior loss: 112220.26\n",
      "     total loss: 23.03\n",
      " valid accuracy: 0.903\n",
      "  test accuracy: 0.896\n",
      "\n",
      "time: 14 m 32 s\n",
      "epoch: 180\n",
      "  labelled loss: 30.84\n",
      "unlabelled loss: 10260.06\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112236.38\n",
      "     total loss: 22.83\n",
      " valid accuracy: 0.906\n",
      "  test accuracy: 0.898\n",
      "\n",
      "time: 15 m 21 s\n",
      "epoch: 190\n",
      "  labelled loss: 21.67\n",
      "unlabelled loss: 10364.85\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112252.56\n",
      "     total loss: 23.02\n",
      " valid accuracy: 0.910\n",
      "  test accuracy: 0.902\n",
      "\n",
      "time: 16 m 9 s\n",
      "epoch: 200\n",
      "  labelled loss: 19.87\n",
      "unlabelled loss: 10293.87\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112268.64\n",
      "     total loss: 22.87\n",
      " valid accuracy: 0.911\n",
      "  test accuracy: 0.904\n",
      "\n",
      "time: 16 m 57 s\n",
      "epoch: 210\n",
      "  labelled loss: 23.63\n",
      "unlabelled loss: 10293.57\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112284.55\n",
      "     total loss: 22.88\n",
      " valid accuracy: 0.914\n",
      "  test accuracy: 0.907\n",
      "\n",
      "time: 17 m 46 s\n",
      "epoch: 220\n",
      "  labelled loss: 21.39\n",
      "unlabelled loss: 10394.27\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112300.50\n",
      "     total loss: 23.08\n",
      " valid accuracy: 0.916\n",
      "  test accuracy: 0.907\n",
      "\n",
      "time: 18 m 34 s\n",
      "epoch: 230\n",
      "  labelled loss: 23.91\n",
      "unlabelled loss: 10327.59\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112315.86\n",
      "     total loss: 22.95\n",
      " valid accuracy: 0.921\n",
      "  test accuracy: 0.914\n",
      "\n",
      "time: 19 m 23 s\n",
      "epoch: 240\n",
      "  labelled loss: 19.07\n",
      "unlabelled loss: 10226.24\n",
      "classifier loss: 0.07\n",
      "     prior loss: 112331.24\n",
      "     total loss: 22.74\n",
      " valid accuracy: 0.922\n",
      "  test accuracy: 0.915\n",
      "\n",
      "time: 20 m 12 s\n",
      "epoch: 250\n",
      "  labelled loss: 16.56\n",
      "unlabelled loss: 10233.44\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112345.51\n",
      "     total loss: 22.75\n",
      " valid accuracy: 0.923\n",
      "  test accuracy: 0.917\n",
      "\n",
      "time: 21 m 0 s\n",
      "epoch: 260\n",
      "  labelled loss: 19.21\n",
      "unlabelled loss: 10191.99\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112360.18\n",
      "     total loss: 22.67\n",
      " valid accuracy: 0.924\n",
      "  test accuracy: 0.918\n",
      "\n",
      "time: 21 m 49 s\n",
      "epoch: 270\n",
      "  labelled loss: 24.27\n",
      "unlabelled loss: 10209.11\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112374.53\n",
      "     total loss: 22.71\n",
      " valid accuracy: 0.928\n",
      "  test accuracy: 0.921\n",
      "\n",
      "time: 22 m 37 s\n",
      "epoch: 280\n",
      "  labelled loss: 19.50\n",
      "unlabelled loss: 10296.08\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112388.20\n",
      "     total loss: 22.88\n",
      " valid accuracy: 0.930\n",
      "  test accuracy: 0.924\n",
      "\n",
      "time: 23 m 26 s\n",
      "epoch: 290\n",
      "  labelled loss: 17.31\n",
      "unlabelled loss: 10206.56\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112402.66\n",
      "     total loss: 22.70\n",
      " valid accuracy: 0.933\n",
      "  test accuracy: 0.926\n",
      "\n",
      "time: 24 m 15 s\n",
      "epoch: 300\n",
      "  labelled loss: 15.27\n",
      "unlabelled loss: 10218.45\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112415.45\n",
      "     total loss: 22.72\n",
      " valid accuracy: 0.934\n",
      "  test accuracy: 0.927\n",
      "\n",
      "time: 25 m 4 s\n",
      "epoch: 310\n",
      "  labelled loss: 18.06\n",
      "unlabelled loss: 10243.83\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112429.17\n",
      "     total loss: 22.77\n",
      " valid accuracy: 0.936\n",
      "  test accuracy: 0.930\n",
      "\n",
      "time: 25 m 52 s\n",
      "epoch: 320\n",
      "  labelled loss: 15.15\n",
      "unlabelled loss: 10318.23\n",
      "classifier loss: 0.08\n",
      "     prior loss: 112442.47\n",
      "     total loss: 22.92\n",
      " valid accuracy: 0.935\n",
      "  test accuracy: 0.930\n",
      "\n",
      "time: 26 m 41 s\n",
      "epoch: 330\n",
      "  labelled loss: 21.41\n",
      "unlabelled loss: 10140.45\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112455.61\n",
      "     total loss: 22.57\n",
      " valid accuracy: 0.938\n",
      "  test accuracy: 0.932\n",
      "\n",
      "time: 27 m 30 s\n",
      "epoch: 340\n",
      "  labelled loss: 14.77\n",
      "unlabelled loss: 10220.02\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112468.10\n",
      "     total loss: 22.72\n",
      " valid accuracy: 0.939\n",
      "  test accuracy: 0.934\n",
      "\n",
      "time: 28 m 19 s\n",
      "epoch: 350\n",
      "  labelled loss: 20.97\n",
      "unlabelled loss: 10281.74\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112480.08\n",
      "     total loss: 22.86\n",
      " valid accuracy: 0.940\n",
      "  test accuracy: 0.936\n",
      "\n",
      "time: 29 m 8 s\n",
      "epoch: 360\n",
      "  labelled loss: 18.76\n",
      "unlabelled loss: 10204.36\n",
      "classifier loss: 0.01\n",
      "     prior loss: 112491.92\n",
      "     total loss: 22.70\n",
      " valid accuracy: 0.939\n",
      "  test accuracy: 0.934\n",
      "\n",
      "time: 29 m 58 s\n",
      "epoch: 370\n",
      "  labelled loss: 29.32\n",
      "unlabelled loss: 10253.24\n",
      "classifier loss: 0.22\n",
      "     prior loss: 112503.81\n",
      "     total loss: 22.84\n",
      " valid accuracy: 0.941\n",
      "  test accuracy: 0.937\n",
      "\n",
      "time: 30 m 47 s\n",
      "epoch: 380\n",
      "  labelled loss: 19.10\n",
      "unlabelled loss: 10171.09\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112514.98\n",
      "     total loss: 22.63\n",
      " valid accuracy: 0.943\n",
      "  test accuracy: 0.938\n",
      "\n",
      "time: 31 m 36 s\n",
      "epoch: 390\n",
      "  labelled loss: 23.38\n",
      "unlabelled loss: 10259.74\n",
      "classifier loss: 0.09\n",
      "     prior loss: 112526.10\n",
      "     total loss: 22.83\n",
      " valid accuracy: 0.941\n",
      "  test accuracy: 0.935\n",
      "\n",
      "time: 32 m 25 s\n",
      "epoch: 400\n",
      "  labelled loss: 23.15\n",
      "unlabelled loss: 10120.77\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112537.80\n",
      "     total loss: 22.54\n",
      " valid accuracy: 0.944\n",
      "  test accuracy: 0.940\n",
      "\n",
      "time: 33 m 14 s\n",
      "epoch: 410\n",
      "  labelled loss: 13.42\n",
      "unlabelled loss: 10093.27\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112548.72\n",
      "     total loss: 22.46\n",
      " valid accuracy: 0.945\n",
      "  test accuracy: 0.940\n",
      "\n",
      "time: 34 m 4 s\n",
      "epoch: 420\n",
      "  labelled loss: 21.20\n",
      "unlabelled loss: 10390.61\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112559.52\n",
      "     total loss: 23.07\n",
      " valid accuracy: 0.946\n",
      "  test accuracy: 0.941\n",
      "\n",
      "time: 34 m 53 s\n",
      "epoch: 430\n",
      "  labelled loss: 21.57\n",
      "unlabelled loss: 10144.41\n",
      "classifier loss: 0.01\n",
      "     prior loss: 112570.61\n",
      "     total loss: 22.58\n",
      " valid accuracy: 0.946\n",
      "  test accuracy: 0.942\n",
      "\n",
      "time: 35 m 43 s\n",
      "epoch: 440\n",
      "  labelled loss: 17.15\n",
      "unlabelled loss: 10265.12\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112580.71\n",
      "     total loss: 22.82\n",
      " valid accuracy: 0.947\n",
      "  test accuracy: 0.942\n",
      "\n",
      "time: 36 m 32 s\n",
      "epoch: 450\n",
      "  labelled loss: 31.78\n",
      "unlabelled loss: 10252.99\n",
      "classifier loss: 0.09\n",
      "     prior loss: 112591.08\n",
      "     total loss: 22.83\n",
      " valid accuracy: 0.948\n",
      "  test accuracy: 0.944\n",
      "\n",
      "time: 37 m 18 s\n",
      "epoch: 460\n",
      "  labelled loss: 17.10\n",
      "unlabelled loss: 10093.38\n",
      "classifier loss: 0.01\n",
      "     prior loss: 112601.41\n",
      "     total loss: 22.47\n",
      " valid accuracy: 0.948\n",
      "  test accuracy: 0.944\n",
      "\n",
      "time: 37 m 59 s\n",
      "epoch: 470\n",
      "  labelled loss: 19.05\n",
      "unlabelled loss: 10147.49\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112611.48\n",
      "     total loss: 22.59\n",
      " valid accuracy: 0.948\n",
      "  test accuracy: 0.944\n",
      "\n",
      "time: 38 m 40 s\n",
      "epoch: 480\n",
      "  labelled loss: 20.25\n",
      "unlabelled loss: 10245.37\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112621.25\n",
      "     total loss: 22.78\n",
      " valid accuracy: 0.951\n",
      "  test accuracy: 0.945\n",
      "\n",
      "time: 39 m 22 s\n",
      "epoch: 490\n",
      "  labelled loss: 26.50\n",
      "unlabelled loss: 10108.02\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112630.91\n",
      "     total loss: 22.52\n",
      " valid accuracy: 0.950\n",
      "  test accuracy: 0.945\n",
      "\n",
      "time: 40 m 4 s\n",
      "epoch: 500\n",
      "  labelled loss: 19.48\n",
      "unlabelled loss: 10081.39\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112640.60\n",
      "     total loss: 22.45\n",
      " valid accuracy: 0.950\n",
      "  test accuracy: 0.947\n",
      "\n",
      "time: 40 m 45 s\n",
      "epoch: 510\n",
      "  labelled loss: 24.73\n",
      "unlabelled loss: 10247.62\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112650.11\n",
      "     total loss: 22.80\n",
      " valid accuracy: 0.951\n",
      "  test accuracy: 0.946\n",
      "\n",
      "time: 41 m 24 s\n",
      "epoch: 520\n",
      "  labelled loss: 22.51\n",
      "unlabelled loss: 10135.76\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112659.64\n",
      "     total loss: 22.57\n",
      " valid accuracy: 0.950\n",
      "  test accuracy: 0.947\n",
      "\n",
      "time: 42 m 3 s\n",
      "epoch: 530\n",
      "  labelled loss: 15.90\n",
      "unlabelled loss: 10059.48\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112668.59\n",
      "     total loss: 22.40\n",
      " valid accuracy: 0.952\n",
      "  test accuracy: 0.947\n",
      "\n",
      "time: 42 m 40 s\n",
      "epoch: 540\n",
      "  labelled loss: 14.95\n",
      "unlabelled loss: 10155.64\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112677.33\n",
      "     total loss: 22.59\n",
      " valid accuracy: 0.952\n",
      "  test accuracy: 0.947\n",
      "\n",
      "time: 43 m 18 s\n",
      "epoch: 550\n",
      "  labelled loss: 19.07\n",
      "unlabelled loss: 10186.23\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112686.00\n",
      "     total loss: 22.66\n",
      " valid accuracy: 0.953\n",
      "  test accuracy: 0.948\n",
      "\n",
      "time: 43 m 56 s\n",
      "epoch: 560\n",
      "  labelled loss: 19.75\n",
      "unlabelled loss: 10155.07\n",
      "classifier loss: 0.09\n",
      "     prior loss: 112694.64\n",
      "     total loss: 22.61\n",
      " valid accuracy: 0.953\n",
      "  test accuracy: 0.949\n",
      "\n",
      "time: 44 m 35 s\n",
      "epoch: 570\n",
      "  labelled loss: 16.25\n",
      "unlabelled loss: 10072.02\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112702.81\n",
      "     total loss: 22.43\n",
      " valid accuracy: 0.953\n",
      "  test accuracy: 0.948\n",
      "\n",
      "time: 45 m 13 s\n",
      "epoch: 580\n",
      "  labelled loss: 19.71\n",
      "unlabelled loss: 10201.58\n",
      "classifier loss: 0.06\n",
      "     prior loss: 112711.27\n",
      "     total loss: 22.70\n",
      " valid accuracy: 0.952\n",
      "  test accuracy: 0.948\n",
      "\n",
      "time: 45 m 51 s\n",
      "epoch: 590\n",
      "  labelled loss: 14.27\n",
      "unlabelled loss: 10293.47\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112719.49\n",
      "     total loss: 22.87\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 46 m 29 s\n",
      "epoch: 600\n",
      "  labelled loss: 21.70\n",
      "unlabelled loss: 10073.72\n",
      "classifier loss: 0.05\n",
      "     prior loss: 112727.34\n",
      "     total loss: 22.45\n",
      " valid accuracy: 0.953\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 47 m 8 s\n",
      "epoch: 610\n",
      "  labelled loss: 17.42\n",
      "unlabelled loss: 10180.49\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112735.61\n",
      "     total loss: 22.65\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.950\n",
      "\n",
      "time: 47 m 45 s\n",
      "epoch: 620\n",
      "  labelled loss: 19.41\n",
      "unlabelled loss: 10328.46\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112743.45\n",
      "     total loss: 22.95\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 48 m 24 s\n",
      "epoch: 630\n",
      "  labelled loss: 20.81\n",
      "unlabelled loss: 10268.72\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112751.32\n",
      "     total loss: 22.83\n",
      " valid accuracy: 0.953\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 49 m 5 s\n",
      "epoch: 640\n",
      "  labelled loss: 20.93\n",
      "unlabelled loss: 10175.63\n",
      "classifier loss: 0.04\n",
      "     prior loss: 112759.04\n",
      "     total loss: 22.65\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 49 m 46 s\n",
      "epoch: 650\n",
      "  labelled loss: 20.55\n",
      "unlabelled loss: 10070.53\n",
      "classifier loss: 0.06\n",
      "     prior loss: 112766.73\n",
      "     total loss: 22.44\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 50 m 27 s\n",
      "epoch: 660\n",
      "  labelled loss: 26.56\n",
      "unlabelled loss: 10137.12\n",
      "classifier loss: 0.05\n",
      "     prior loss: 112774.71\n",
      "     total loss: 22.59\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 51 m 8 s\n",
      "epoch: 670\n",
      "  labelled loss: 13.40\n",
      "unlabelled loss: 10098.21\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112782.02\n",
      "     total loss: 22.48\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.952\n",
      "\n",
      "time: 51 m 49 s\n",
      "epoch: 680\n",
      "  labelled loss: 24.04\n",
      "unlabelled loss: 9979.59\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112789.38\n",
      "     total loss: 22.27\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.953\n",
      "\n",
      "time: 52 m 30 s\n",
      "epoch: 690\n",
      "  labelled loss: 25.77\n",
      "unlabelled loss: 10207.15\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112796.32\n",
      "     total loss: 22.72\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.952\n",
      "\n",
      "time: 53 m 11 s\n",
      "epoch: 700\n",
      "  labelled loss: 21.11\n",
      "unlabelled loss: 10223.89\n",
      "classifier loss: 0.07\n",
      "     prior loss: 112803.77\n",
      "     total loss: 22.75\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.952\n",
      "\n",
      "time: 53 m 52 s\n",
      "epoch: 710\n",
      "  labelled loss: 16.42\n",
      "unlabelled loss: 10132.06\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112810.74\n",
      "     total loss: 22.55\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.953\n",
      "\n",
      "time: 54 m 33 s\n",
      "epoch: 720\n",
      "  labelled loss: 22.27\n",
      "unlabelled loss: 10061.42\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112817.60\n",
      "     total loss: 22.42\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.952\n",
      "\n",
      "time: 55 m 13 s\n",
      "epoch: 730\n",
      "  labelled loss: 16.30\n",
      "unlabelled loss: 10145.34\n",
      "classifier loss: 0.04\n",
      "     prior loss: 112824.23\n",
      "     total loss: 22.58\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.951\n",
      "\n",
      "time: 55 m 54 s\n",
      "epoch: 740\n",
      "  labelled loss: 24.63\n",
      "unlabelled loss: 10178.44\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112831.18\n",
      "     total loss: 22.66\n",
      " valid accuracy: 0.954\n",
      "  test accuracy: 0.952\n",
      "\n",
      "time: 56 m 35 s\n",
      "epoch: 750\n",
      "  labelled loss: 25.04\n",
      "unlabelled loss: 10112.99\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112837.65\n",
      "     total loss: 22.53\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.953\n",
      "\n",
      "time: 57 m 17 s\n",
      "epoch: 760\n",
      "  labelled loss: 20.62\n",
      "unlabelled loss: 10114.65\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112844.37\n",
      "     total loss: 22.53\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.953\n",
      "\n",
      "time: 57 m 59 s\n",
      "epoch: 770\n",
      "  labelled loss: 18.39\n",
      "unlabelled loss: 10127.73\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112850.77\n",
      "     total loss: 22.55\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.953\n",
      "\n",
      "time: 58 m 40 s\n",
      "epoch: 780\n",
      "  labelled loss: 23.28\n",
      "unlabelled loss: 10128.51\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112857.15\n",
      "     total loss: 22.56\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 59 m 22 s\n",
      "epoch: 790\n",
      "  labelled loss: 20.08\n",
      "unlabelled loss: 10044.56\n",
      "classifier loss: 0.35\n",
      "     prior loss: 112863.94\n",
      "     total loss: 22.42\n",
      " valid accuracy: 0.958\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 60 m 3 s\n",
      "epoch: 800\n",
      "  labelled loss: 22.05\n",
      "unlabelled loss: 10190.31\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112870.66\n",
      "     total loss: 22.68\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 60 m 45 s\n",
      "epoch: 810\n",
      "  labelled loss: 15.47\n",
      "unlabelled loss: 10029.87\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112877.08\n",
      "     total loss: 22.35\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 61 m 26 s\n",
      "epoch: 820\n",
      "  labelled loss: 21.86\n",
      "unlabelled loss: 10151.43\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112883.30\n",
      "     total loss: 22.60\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 62 m 7 s\n",
      "epoch: 830\n",
      "  labelled loss: 21.51\n",
      "unlabelled loss: 10000.89\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112889.45\n",
      "     total loss: 22.30\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 62 m 48 s\n",
      "epoch: 840\n",
      "  labelled loss: 22.85\n",
      "unlabelled loss: 9891.68\n",
      "classifier loss: 0.08\n",
      "     prior loss: 112895.43\n",
      "     total loss: 22.09\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 63 m 29 s\n",
      "epoch: 850\n",
      "  labelled loss: 24.71\n",
      "unlabelled loss: 10179.12\n",
      "classifier loss: 0.07\n",
      "     prior loss: 112901.61\n",
      "     total loss: 22.67\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 64 m 10 s\n",
      "epoch: 860\n",
      "  labelled loss: 23.11\n",
      "unlabelled loss: 10023.37\n",
      "classifier loss: 0.02\n",
      "     prior loss: 112907.19\n",
      "     total loss: 22.35\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.955\n",
      "\n",
      "time: 64 m 50 s\n",
      "epoch: 870\n",
      "  labelled loss: 16.58\n",
      "unlabelled loss: 10198.72\n",
      "classifier loss: 0.03\n",
      "     prior loss: 112913.02\n",
      "     total loss: 22.69\n",
      " valid accuracy: 0.955\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 65 m 27 s\n",
      "epoch: 880\n",
      "  labelled loss: 17.63\n",
      "unlabelled loss: 10106.26\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112919.01\n",
      "     total loss: 22.51\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 66 m 4 s\n",
      "epoch: 890\n",
      "  labelled loss: 17.97\n",
      "unlabelled loss: 10143.33\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112924.92\n",
      "     total loss: 22.58\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 66 m 40 s\n",
      "epoch: 900\n",
      "  labelled loss: 19.92\n",
      "unlabelled loss: 10081.02\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112930.34\n",
      "     total loss: 22.46\n",
      " valid accuracy: 0.958\n",
      "  test accuracy: 0.956\n",
      "\n",
      "time: 67 m 17 s\n",
      "epoch: 910\n",
      "  labelled loss: 15.12\n",
      "unlabelled loss: 10106.23\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112936.05\n",
      "     total loss: 22.50\n",
      " valid accuracy: 0.957\n",
      "  test accuracy: 0.957\n",
      "\n",
      "time: 67 m 55 s\n",
      "epoch: 920\n",
      "  labelled loss: 17.60\n",
      "unlabelled loss: 9935.67\n",
      "classifier loss: 0.00\n",
      "     prior loss: 112941.41\n",
      "     total loss: 22.17\n",
      " valid accuracy: 0.956\n",
      "  test accuracy: 0.956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils import (load_mnist_split, create_semisupervised, ssl_batch_gen, time_since)\n",
    "from vae import VAE\n",
    "\n",
    "'''\n",
    "    here are the config params for the experiment.\n",
    "'''\n",
    "data_size = 50000\n",
    "batch_size = 500\n",
    "n_labelled = 100\n",
    "n_epoch = 1000\n",
    "\n",
    "np.random.seed(31415)\n",
    "tf.set_random_seed(31415)\n",
    "    \n",
    "import pickle\n",
    "y_l     = pickle.load(open('dumps/y_l.pkl','rb'))\n",
    "y_u     = pickle.load(open('dumps/y_u.pkl','rb'))\n",
    "valid_y = pickle.load(open('dumps/y_v.pkl','rb'))\n",
    "test_y  = pickle.load(open('dumps/y_t.pkl','rb'))\n",
    "\n",
    "data_y_l = np.where(y_l     == 1)[1]\n",
    "y_u      = np.where(y_u     == 1)[1]\n",
    "valid_y  = np.where(valid_y == 1)[1]\n",
    "test_y   = np.where(test_y  == 1)[1]\n",
    "\n",
    "mu_l, logvar_l = pickle.load(open('dumps/x_l.pkl','rb'))\n",
    "mu_u, logvar_u = pickle.load(open('dumps/x_u.pkl','rb'))\n",
    "mu_v, logvar_v = pickle.load(open('dumps/x_v.pkl','rb'))\n",
    "mu_t, logvar_t = pickle.load(open('dumps/x_t.pkl','rb'))\n",
    "\n",
    "min_std = 0.1\n",
    "selected_dims = np.std(mu_u, axis = 0) > min_std\n",
    "\n",
    "mu_l, logvar_l = get_dims(mu_l, selected_dims), get_dims(logvar_l, selected_dims)\n",
    "mu_u, logvar_u = get_dims(mu_u, selected_dims), get_dims(logvar_u, selected_dims)\n",
    "mu_v, logvar_v = get_dims(mu_v, selected_dims), get_dims(logvar_v, selected_dims)\n",
    "mu_t, logvar_t = get_dims(mu_t, selected_dims), get_dims(logvar_t, selected_dims)\n",
    "\n",
    "data_x_l = sample(mu_l, logvar_l)\n",
    "data_x_u = sample(mu_u, logvar_u)\n",
    "valid_x  = sample(mu_v, logvar_v)\n",
    "test_x   = sample(mu_t, logvar_t)\n",
    "\n",
    "x_dim = data_x_u.shape[1]\n",
    "g = tf.Graph()\n",
    "# Set config for tensorflow session.\n",
    "tf_config = tf.ConfigProto(\n",
    "    device_count = {'GPU': 1}, # single gpu\n",
    ")\n",
    "tf_config.gpu_options.allow_growth=True\n",
    "with g.as_default():\n",
    "    with tf.Session(config = tf_config) as sess:\n",
    "        model = SSL(x_dim = x_dim)\n",
    "        var_list = model.global_vars()\n",
    "        sess.run(tf.variables_initializer(var_list))\n",
    "\n",
    "        start = time.time()\n",
    "        for epoch in range(10000):\n",
    "            l_batch_gen, u_batch_gen = ssl_batch_gen(data_x_l, data_y_l, data_x_u, 500, 1)\n",
    "\n",
    "            for l_batch, u_batch in zip(l_batch_gen, u_batch_gen):\n",
    "                x_l, y_l = zip(*l_batch)\n",
    "                x_u = zip(*u_batch)[0]\n",
    "                loss, loss_clf, loss_l, loss_u, loss_p = model.optimize(sess, x_l, y_l, x_u)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                pred_valid = model.predict(valid_x, sess)\n",
    "                pred_test  = model.predict(test_x,  sess)\n",
    "                accuracy_valid = accuracy_score(valid_y, pred_valid)\n",
    "                accuracy_test  = accuracy_score(test_y,  pred_test)\n",
    "\n",
    "                print('time: %s' % time_since(start))\n",
    "                print('epoch: %d' % epoch)\n",
    "                print('  labelled loss: %.2f' % loss_l)\n",
    "                print('unlabelled loss: %.2f' % loss_u)\n",
    "                print('classifier loss: %.2f' % loss_clf)\n",
    "                print('     prior loss: %.2f' % loss_p)\n",
    "                print('     total loss: %.2f' % loss)\n",
    "                print(' valid accuracy: %.3f' % accuracy_valid)\n",
    "                print('  test accuracy: %.3f' % accuracy_test)\n",
    "                print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
